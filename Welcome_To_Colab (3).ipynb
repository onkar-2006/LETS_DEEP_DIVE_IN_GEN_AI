{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#now we start the implimentation of the build the gen ai project using the openai or the opensource model from the groq"
      ],
      "metadata": {
        "id": "g6T6iSDmgkWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain\n",
        "import os\n",
        "load_dotenv()\n",
        "os.environ[\"open_ai_key\"]=os.getenv(\"OPENAI_KEY\")\n",
        "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
        "os.environ[\"LANGCHAIN_TRACEING_ID\"]='true'\n",
        "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJOECT\")"
      ],
      "metadata": {
        "id": "qIPsTYcxgxqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#the libraries need for run the server on ur pc\n",
        "#create the file for download the all the libraries\n",
        "#saved that file using the requirement.text\n",
        "langchain\n",
        "python-dotenv\n",
        "langchain-openai\n",
        "ipykernel"
      ],
      "metadata": {
        "id": "36P5usXzhbe2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAI#it is the for the normal used for that perpose\n",
        "from langchain_openai import ChatOpenAI\n",
        "llm=ChatOpenAI(\"gpt-40\")\n",
        "orint(llm)"
      ],
      "metadata": {
        "id": "Md9uihbOh5Jo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "now the model is readdy lets start the explore the model"
      ],
      "metadata": {
        "id": "pYCCMwy7jOMk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!Pip install ipykernel"
      ],
      "metadata": {
        "id": "rnFitwZ7ifhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#the invoke method is used to test\n",
        "result=llm.invoke(\"what is u know about the shri chhratrapati shivaji maharaj\")"
      ],
      "metadata": {
        "id": "oGXiTv64jahY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#chat promt\n",
        "from langchain.core.promts import ChatPromptTemplate\n",
        "promts=ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"you are the expret ai engineer  have to give ans like that \"),\n",
        "        (\"user\",\"{input}\")\n",
        "    ]\n",
        ")\n",
        "promts"
      ],
      "metadata": {
        "id": "KQHitSZwjuHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create the chain -->it is an AIMessage\n",
        "chain=promt|llm\n",
        "responce=chain.invoke({\"input\":\"can u tell me about the langsmith\"})"
      ],
      "metadata": {
        "id": "zSoMzc4KlPQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "responce"
      ],
      "metadata": {
        "id": "x3CmxFJZlkl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Outputparser --> the output parser will help to display the output\n",
        "from langchain_core.outputparsers import strOutputParser\n",
        "output_parser=strOutputParser\n",
        "chain=promt|llm|output_parser\n",
        "\n",
        "responce=chain.invoke({\"input\":\"tell me about the langsmith\"})\n",
        "responce"
      ],
      "metadata": {
        "id": "OwQ9gLs8l1Zr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JQi0GCYPmw-t"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}