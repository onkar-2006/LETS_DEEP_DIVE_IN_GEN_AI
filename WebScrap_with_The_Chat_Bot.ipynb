{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# ***INSTALLATION OF SOME LIBRARIES***\n",
        "\n"
      ],
      "metadata": {
        "id": "9dChqOeY5PkA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_groq"
      ],
      "metadata": {
        "id": "o3Cij4NW1y3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community"
      ],
      "metadata": {
        "id": "PgofXTfE1day"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_huggingface"
      ],
      "metadata": {
        "id": "aUbLG-3o2GYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **IMPORT THE LIBRARIES**"
      ],
      "metadata": {
        "id": "ifUrcXEC4QyG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hqjlrdpDl0V0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain_groq import ChatGroq\n",
        "from dotenv import load_dotenv\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_community.document_loaders import WebBasedLoader\n",
        "groq_api_key=os.getenv(\"GROQ_API_KEY\")\n",
        "os.environ[\"HF_TOKEN\"]=os.getenv(\"HF_TOKEN\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***FETCHING THE DATA BY WEBSCRAP***"
      ],
      "metadata": {
        "id": "9xOq5HOE4WvX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import bs4\n",
        "data=WebBasedLoader(web_paths=\"www.huggingface.com\",\n",
        "                    bs_kwargs=dict(\n",
        "                        parse_only=bs4.SoupStrainer(\n",
        "                            class_=(\"post-content\" , \"post-title\" , \"post-header\")\n",
        "                        )\n",
        "                    ))"
      ],
      "metadata": {
        "id": "_7Qq2odCmz3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***SPLIT THE DATA INTO CHUNK***"
      ],
      "metadata": {
        "id": "McJGyQ-a4gh-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "splitter=RecursiveCharacterTextSplitter(chunk_size=500  ,chunk_overlap=100)\n",
        "final_document=splitter.split_document(data)\n"
      ],
      "metadata": {
        "id": "McLLsLaDnkf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***LOADING THE EMBEDDING***"
      ],
      "metadata": {
        "id": "MdWme9mQ4mGq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"HF_TOKEN\"]=os.getenv(\"HF_TOKEN\")\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "embedding=HuggingFaceEmbeddings(model_name=\"ganna-2b\")\n",
        "\n"
      ],
      "metadata": {
        "id": "zEaQhFt4oFoH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api_key=os.getenv(\"GROQ_API_KEY\")\n",
        "llm=ChatGroq(groq_api_key=api_key , model_name=\"lama3-8b-8192\")"
      ],
      "metadata": {
        "id": "8eeny9n0o4Bs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***CREATE_THE VECTORSTORE***"
      ],
      "metadata": {
        "id": "T3J4hbid4vDW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_chroma import Chroma\n",
        "vectorstore=Chroma.from_documents(documents=final_document,embedding=embedding)\n",
        "retriever=vectorstore.as_retriever()\n",
        "retriever"
      ],
      "metadata": {
        "id": "RAbsxzFBoy5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt=\n",
        "(\"\"\"\n",
        " you are an assistant for quetion -annwering tasks.\n",
        " use the follwing pices o contect to answer the qquetion of dont kno the answer\n",
        " say that you dont know use maximum three sentences maximun and keep the answer concise {context}\n",
        " \"\"\" )"
      ],
      "metadata": {
        "id": "gA9-XHOFp0kF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***CREATE_A_PROMPT_TEMPLATE***"
      ],
      "metadata": {
        "id": "q6vT-ne-40mg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "promt=ChatPromptTemplate(\n",
        "    [\n",
        "        (\"system\",system_prompt),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "iTGwiw2sq-D0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***CREATE THE RETRIVEAL CHAIN***"
      ],
      "metadata": {
        "id": "mWdFfyCs496I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_document_chain\n",
        "quetion_answer_chain=create_stuff_document_chain(llm, promt)\n",
        "rag_chain=create_retrieval_chain(retriever ,quetion_answer_chain)"
      ],
      "metadata": {
        "id": "7tGhjywsrO7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "responce=rag_chain.invoke(\"input\", \"what is info in the given text\")"
      ],
      "metadata": {
        "id": "qUx0wl4drykR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#adding the history in that"
      ],
      "metadata": {
        "id": "DyXqXpqbsJcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***GIVEN CODE IS FOR THE ADDING  THE CHAT-HISTORY***"
      ],
      "metadata": {
        "id": "vKyp7jsP5E4w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import create_history_aware_retriever\n",
        "from langchain_core.prompts import MessagesPlaceholder\n",
        "\n",
        "\n",
        "contextualize_q_system_prompt=(\n",
        "    \"given a chat history and the leest user wuritom wihhc mrhg refrence in th chat hidtory formulate  a standalone quetion which can be understood without and chat history do not answer the qieto jusgt reformulate it id needed and othete return it as is\"\n",
        ")"
      ],
      "metadata": {
        "id": "QAxR1xD5sPip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context_q_prompt=ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\" ,contextualize_q_system_prompt ),\n",
        "        MessagesPlaceholder(\"chat_history\"),\n",
        "        (\"human\", \"{input}\")\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "9NVE748Tujwy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_aware_retriver=create_history_aware_retriever(llm , retriever , context_q_prompt)"
      ],
      "metadata": {
        "id": "x8lvYDOxvDvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_prompt= ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_prompt),\n",
        "        MessagesPlaceholder(\"chat_history\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "R4DvDGYovigl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question_answer_chain=create_stuff_document_chain(llm,qa_prompt)\n",
        "rag_chain=create_retrieval_chain(history_aware_retriver,question_answer_chain)"
      ],
      "metadata": {
        "id": "HmD2AEvmv6Tu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import AIMessage,HumanMessage\n",
        "chat_history=[]\n",
        "quetion=\"what is the self-reflection\"\n",
        "responce1=rag_chain.invoke({\"input\":quetion , \"chat_history\":chat_history})\n",
        "\n",
        "chat_history.extend(\n",
        "    [\n",
        "        HumanMessage(content=quetion),\n",
        "        AIMessage(content=responce1[\"answer\"])\n",
        "    ]\n",
        ")\n",
        "\n",
        "qution_2=\"tell me more about it\"\n",
        "responce2=rag_chain.invoke({\"input\":quetion , \"chat_history\":chat_history})\n",
        "print(responce2[\"answer\"])"
      ],
      "metadata": {
        "id": "ckOq43NrwHjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history\n",
        "from langchain_community.chat_message_histories import ChatMessageHistory\n",
        "from langchain_core.chat_history import BaseChatMessageHistory\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "store={}"
      ],
      "metadata": {
        "id": "zy1wHwLdxf5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_session_history(session_id : str)-->BaseChatMessageHistory:\n",
        "  if session_id not in store:\n",
        "    store[session_id]=ChatMessageHistory()\n",
        "  return store[session_id]"
      ],
      "metadata": {
        "id": "qv8zs1pyywc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversional_rag_chain=RunnableWithMessageHistory(\n",
        "    rag_chain ,\n",
        "    get_session_history,\n",
        "    inout_message_key=\"input\",\n",
        "    history_messages_key=\"chat_history\",\n",
        "    output_messages_key=\"answer\",\n",
        "    )"
      ],
      "metadata": {
        "id": "bDwD9htyzHOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversional_rag_chain.invoke(\n",
        "    {\"input\":\"what is the task decomposition\"},\n",
        "    config={\n",
        "        \"configurable\":{\"session_id\":\"abc123\"}\n",
        "\n",
        "    },\n",
        "    )[\"answer\"]"
      ],
      "metadata": {
        "id": "6mZQLBMSzwnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversional_rag_chain.invoke(\n",
        "    {\"input\":\"what are the comman way og doing it\"},\n",
        "    config={\"configureble\":{\"session_id\":\"abc123\"}}\n",
        ")[\"answer\"]"
      ],
      "metadata": {
        "id": "GLcYhPCb0dyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OjrVONAd02ma"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}