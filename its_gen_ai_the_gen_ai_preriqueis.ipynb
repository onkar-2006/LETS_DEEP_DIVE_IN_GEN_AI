{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Dz5zmJyrdK3"
      },
      "outputs": [],
      "source": [
        "now the first step to build any gen ai aplication is th e\n",
        "load th edata\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "loader=TextLoader(\"path.txt\")\n",
        "data=loader.load()\n",
        "data\n",
        "\n",
        "if that is in the pdf file\n",
        "from langchain_community.document_loaders  import pyPDFLoader\n",
        "loader=pyPDFLoader(\"textcv.pdf\")\n",
        "data=loader.load()\n",
        "data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "niw the next step after data loadins is to convert that data into the smaller chunk\n",
        "the chunk is nothing but the set of the words or the sentenxce\n",
        "\n",
        "there are the diffrent type of the spitting tequnics are used to convert the document into chunk\n",
        "the first tequenic is the the character text splitte recursive characterr text splittter\n",
        "recursive json splitter\n",
        "also the  Htmlbased splitter\n",
        "so lets start the deep dive in that\n",
        "\n",
        "from langchain_text_splitter import RecursiveCharacterTextSplitter\n",
        "text_splitter=RecursiveCharacterTextSplitter(chunk_size=100 , chunk_overlap=100)\n",
        "splitted_text=text_splitter.split_document\n",
        "splitted_text=text_splitter.create_document\n",
        "\n",
        "from langchain_text_splitter import CharacterTextSplitter\n",
        "splitter=CharacterTextSplitter(chunk_size 1000 , chunk_overlap=100)\n",
        "splitted_text=splitter.splite_document(text)\n",
        "splitted_text\n",
        "\n",
        "splitted_document\n",
        "splitted_document\n"
      ],
      "metadata": {
        "id": "jlp8FPlUFF7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frist step is to create the envoirement varibel\n",
        "import os\n",
        "from dotenv import load_dotenv()\n",
        "load_dotenv()\n"
      ],
      "metadata": {
        "id": "_iuOa7OQMGJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"open_ALl_API_KEy\"]=os.getenv(\"OPEN_AI_API_KEY\")\n"
      ],
      "metadata": {
        "id": "d_6apUIaMXK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "now the spkitted docuemt is in the from of the text as we know the computer do not know the english so convert that words  into the vector\n",
        "or in the numeric form\n",
        "1.AIembeddibg\n",
        "2.allamaembedding\n",
        "3.huggingface embedding\n",
        "\n",
        "text\"this ia the sample text\"\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "embedding=OpenAIEmbeddings(model=\"gemini-2b\")\n",
        "embedded_text=embedding.embed_query(text)\n",
        "'\n",
        "form langchain_community.embeddings import OllamaEmbeddings\n",
        "model=(\n",
        "    model=\"gamma-2b-9p\",\n",
        ")\n",
        "model.embed_documents(\"the name of the poetry is muze jine do \")\n",
        "\n",
        "\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "embedding=HuggingFaceEmbeddings()\n",
        "\n",
        "retriver=db.as_retriever()\n",
        "docs=retriver.invoke(qeury)\n",
        "docs[0].page_context\n",
        "\n",
        "docs_and_score=bd.similarity_search_with_score(query)\n",
        "docs_and_score\n",
        "\n",
        "docs_vector=db.similarity_search_by_vector(embedding_vector)\n"
      ],
      "metadata": {
        "id": "8m2e-5OvJ13Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cSJcoYuyXF49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores import chroma\n",
        "db=chroma.from_document(final_document , embedding_1024)\n"
      ],
      "metadata": {
        "id": "zpzb8H70PZKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "after fedding the document in the model the lets check whether it work properly or not\n",
        "query =\"this is the first step of the code \"\n",
        "db.search_similarity(query)"
      ],
      "metadata": {
        "id": "hB_tbXddVIic"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}