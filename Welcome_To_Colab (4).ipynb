{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#now we start the implimentation of the build the gen ai project using the openai or the opensource model from the groq"
      ],
      "metadata": {
        "id": "g6T6iSDmgkWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain\n",
        "import os\n",
        "import langchain_community\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "os.environ[\"open_ai_key\"]=os.getenv(\"OPENAI_KEY\")\n",
        "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
        "os.environ[\"LANGCHAIN_TRACEING_ID\"]='true'\n",
        "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJOECT\")"
      ],
      "metadata": {
        "id": "qIPsTYcxgxqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#the libraries need for run the server on ur pc\n",
        "#create the file for download the all the libraries\n",
        "#saved that file using the requirement.text\n",
        "langchain\n",
        "python-dotenv\n",
        "langchain-openai\n",
        "ipykernel"
      ],
      "metadata": {
        "id": "36P5usXzhbe2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAI#it is the for the normal used for that perpose\n",
        "from langchain_openai import ChatOpenAI\n",
        "llm=ChatOpenAI(\"gpt-40\")\n",
        "orint(llm)"
      ],
      "metadata": {
        "id": "Md9uihbOh5Jo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "now the model is readdy lets start the explore the model"
      ],
      "metadata": {
        "id": "pYCCMwy7jOMk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!Pip install ipykernel"
      ],
      "metadata": {
        "id": "rnFitwZ7ifhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#the invoke method is used to test\n",
        "result=llm.invoke(\"what is u know about the shri chhratrapati shivaji maharaj\")"
      ],
      "metadata": {
        "id": "oGXiTv64jahY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#chat promt\n",
        "from langchain.core.promts import ChatPromptTemplate\n",
        "promts=ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"you are the expret ai engineer  have to give ans like that \"),\n",
        "        (\"user\",\"{input}\")\n",
        "    ]\n",
        ")\n",
        "promts"
      ],
      "metadata": {
        "id": "KQHitSZwjuHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create the chain -->it is an AIMessage\n",
        "chain=promt|llm\n",
        "responce=chain.invoke({\"input\":\"can u tell me about the langsmith\"})"
      ],
      "metadata": {
        "id": "zSoMzc4KlPQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "responce"
      ],
      "metadata": {
        "id": "x3CmxFJZlkl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Outputparser --> the output parser will help to display the output\n",
        "from langchain_core.outputparsers import strOutputParser\n",
        "output_parser=strOutputParser\n",
        "chain=promt|llm|output_parser\n",
        "\n",
        "responce=chain.invoke({\"input\":\"tell me about the langsmith\"})\n",
        "responce"
      ],
      "metadata": {
        "id": "OwQ9gLs8l1Zr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JQi0GCYPmw-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# lets start the building the genai application by using the LANGCHAIN"
      ],
      "metadata": {
        "id": "lpNNCnWrnX5B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "os.environ[\"open_ai_key\"]=os.getenv(\"OPENAI_KEY\")\n",
        "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
        "os.environ[\"LANGCHAIN_TRACEING_ID\"]='true'\n",
        "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJOECT\")"
      ],
      "metadata": {
        "id": "vygIT5QAnf3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "this application basically build by with the hekp of the webscrape the webscrape is process in which we faced the data from the webpage so for the websrape we need one library call the buitifulsup"
      ],
      "metadata": {
        "id": "tBQryzx_n_61"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import bs4\n",
        "from langchain_community.document_loaders import WebBasedLoader\n",
        "loader=WebBasedLoder(\"the link if any page with u want to scrap\").load()\n",
        "document=loader.load()\n",
        "document"
      ],
      "metadata": {
        "id": "mKllRfRqoZ86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "text_splitter=RecursiveCharacterTextSplitter(chunk_size-2000 , chunk_overlap=300)\n",
        "document=text_splitter.split_documents(document)"
      ],
      "metadata": {
        "id": "iWHqYJC0py97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document"
      ],
      "metadata": {
        "id": "SNbBHCvbsC_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.openai import OpenAIEmbeddings\n",
        "embedding=OpenAIEmbeddings()"
      ],
      "metadata": {
        "id": "Li9KJlc8sIHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#we are almost reach toword the end of build of the model\n",
        "#the next step is to store the model somewhere called the FAISS vector database\n",
        "from langchain_community.vectorstores import FAISS\n",
        "vector_database=FAISS.from_documents(document , embedding)"
      ],
      "metadata": {
        "id": "qIFJkQFTwXVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#next step is give the query to test the model\n",
        "query=\"this is the sample text\"\n",
        "result=vector_database.search_similarity(query)\n",
        "result[0].page_count"
      ],
      "metadata": {
        "id": "XQi-G5VQwl0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#the next step is the retrival chain or the document chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_core.promts import ChatPromptTemplate\n",
        "promt=ChatPromptTemplate(\n",
        "    \"\"\"answer the follwing quetion properly:\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "xwJ3cHkGxsFI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}