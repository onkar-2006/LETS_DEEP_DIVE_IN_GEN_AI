# LETS_DEEP_DIVE_IN_GEN_AI
new course
00:25 ğŸ“ Introduction to Generative AI Community Session
02:14  ğŸ“š Dashboard Walkthrough and Enrollment Process 
04:19  ğŸ“‹ Curriculum Overview and Instructor Introduction
07:42  ğŸ“Š Detailed Curriculum Breakdown
16:49  ğŸ§  Preparing for Generative AI and LLM Introduction
23:26  ğŸ§  Basics of Deep Learning
27:52 ğŸ¤– Neural Network Architectures Overview
32:07 ğŸ“Š Introduction to Generative AI
33:28 ğŸ“ Generative AI Models and Applications
46:12 ğŸ§  Overview of Text and Image Generation
56:31 ğŸ”„ Addressing Sequence Mapping Issues
01:11:52 ğŸ§  Understanding the Transformer Architecture
01:17:46 ğŸ”„ Discriminative vs Generative Models
01:25:00 ğŸš€ Milestones in Large Language Models (LLMs)
01:44:02 ğŸ“š Accessing Resources and Engaging with the Community
01:53:42 ğŸš€ Overview of Course Enrollment and Dashboard Setup
01:56:15 ğŸ“ Agenda for Today's Session
02:06:02 ğŸŒ Introduction to OpenAI: History, Goals, and Milestones
02:17:19 ğŸ“Š Introduction to OpenAI's API
02:28:29 ğŸ’¼ Job Opportunities and Interview Insights
02:38:19 ğŸ“Š Checking Environment and Installing Jupyter Notebook
02:57:50 ğŸ’» Using the OpenAI Playground and setting up API keys
03:04:15 ğŸ® Exploring the OpenAI Playground and its functionalities
03:10:47 ğŸ¤– Understanding chat completion API and function calling
03:29:08 ğŸ’¡ Understanding tokenization and pricing in OpenAI API.
03:41:05 ğŸ§© Prompt Templating with Hugging Face
03:44:03 ğŸ’» Project Development Setup and Flask Integration
04:01:10 ğŸ–¥ Calling Chat Completion API
04:22:04 ğŸ–¥ Extracting Textual Descriptions Using API Calls
04:42:10 ğŸ“ Extracting Origin and Destination from Arguments
04:43:59 ğŸ›« Retrieving Flight Details
05:03:21 ğŸ’» Introduction to Function Calling and API Integration
05:10:05 ğŸ¤– Utilizing Len Chain for AI Prompting
05:34:50 ğŸ§© Features and Capabilities of Len Chain
05:42:40 ğŸ“ Practical Implementation and Use Cases
05:49:34 ğŸ“ Creating Prompt Templates
05:57:15 ğŸ¤– Utilizing Agents for Real-time Information Extraction
06:09:52 ğŸ›  API Access and Documentation
06:13:07 ğŸ–¥ Implementing API Calls in Code
06:15:24 ğŸ“Š Real-Time Information Retrieval with Sur API
06:17:18 ğŸ“š Accessing Wikipedia Information
06:24:10 ğŸ“„ Exploring Langchain Documentation
06:47:00 ğŸ”— Sequential Chaining in LLM
06:52:10 ğŸ§© Utilizing Sequential Chains in AI Strategy
07:24:41 ğŸ›  Len chain project implementation agenda
08:21:35 ğŸ¤– Setting up Hugging Face Hub and accessing models
08:30:38 ğŸ“¦ Installation and library setup for Hugging Face
08:42:01 ğŸ“š Understanding open-source model usage
08:46:18 ğŸ“ Steps to download and utilize models locally
08:54:42 ğŸ¤– Introduction to using LennChain for generating text
08:58:12 ğŸ’¡ Exploring different prompts and models for text generation
09:06:32 ğŸš€ Announcement of upcoming sessions and resources for learning
09:25:11 ğŸš€ Publishing Code to GitHub
09:37:01 ğŸ’» Setting up Virtual Environment and .gitignore
09:42:00 ğŸ“‹ Listing Project Requirements in requirements.txt
09:48:43 ğŸ“¦ Structuring Local Package with init.py
09:58:41 ğŸ’» Installing Python packages and managing dependencies
10:06:02 ğŸ“‚ Exploring package metadata and project structure
10:10:07 ğŸ›  Configuring API keys and environment variables
10:24:27 ğŸ§© Setting Up the Environment for LLM Integration
10:30:24 ğŸ”— Creating a Prompt Template for Quiz Evaluation
10:34:46 ğŸ¤– Connecting Components Using LLM Chain and Sequential Chain
10:40:25 ğŸ›  Loading Data and Reading Text from a File
10:46:41 ğŸ›  Explaining the usage of OpenAI callback for token tracking in LlamaChain
11:06:46 ğŸ“ Project setup and agenda overview
11:11:09 ğŸ›  Adding files to project structure
11:28:38 ğŸ”’ Setting Up Logging in Python
11:41:24 ğŸ“ Using GitHub and Neuro Lab for Project Development
11:51:33 ğŸ›  Setting up Virtual Environment and Installing Requirements
11:58:36 ğŸ’» Setting up Project Files and Importing Dependencies
12:24:59 ğŸ›  Finalizing Application Structure
12:43:31 ğŸ§© Generating MCQs and Displaying Results
13:02:00 ğŸ“Š Demo and Troubleshooting Streamlit Application
13:04:26 ğŸ–¥ Explanation of application UI and code structure
13:06:31 ğŸš€ Tomorrow's agenda: Deployment and introduction to Vector Databases
13:12:12 ğŸ“Š Generating MCQs from text data
13:16:22 ğŸ’» Preparation for AWS EC2 instance deployment
13:23:22 ğŸš€ Starting with Generative AI
13:24:06 ğŸ›  Setting up AWS EC2 Instance
13:37:04 ğŸ“‚ Cloning and Configuring Repository
13:40:55 ğŸ— Managing Environment Variables
13:44:44 ğŸš€ Running the Application
13:49:09 ğŸ“„ Saving generated quizzes in various formats
13:53:48 ğŸš€ Deployment process overview and instructions
14:09:47 ğŸ§® Understanding Vectors in 2D and 3D Spaces
14:15:08 ğŸ“Š Encoding Techniques for Data Representation
14:19:06 ğŸ“ Introduction to Embedding Concept
14:32:02 ğŸ§  Understanding Vocabulary and One-Hot Encoding
14:47:39 ğŸ“Š Introduction to Vector Databases and Practical Implementation
14:53:41 ğŸ“š Enrollment Process and Dashboard Overview
15:00:41 ğŸ’» Accessing Additional Resources and Video Recordings
15:20:15 ğŸ“‰ Challenges with Traditional Databases
15:38:08 ğŸ—ƒ Use Cases of Vector Databases
15:57:27 ğŸ–¥ Setting up code sharing and library installation
16:00:56 ğŸ“ Creating and uploading folders/files, troubleshooting file size
16:06:52 ğŸ“‘ Loading PDF data, text chunking, and preprocessing
16:19:34 ğŸ“ Extracting Embeddings with OpenAI
16:29:37 ğŸ’» Exploring Pinecone Features and Pricing
16:42:28 ğŸ§¬ Implementing Similarity Search with Vector Databases
17:11:45 ğŸ“ Course Curriculum Overview
17:19:32 ğŸ’» Setting Up and Exploring Chroma DB in Jupyter Notebook
17:24:31 ğŸ” Overview of Chroma DB on GitHub
17:26:35 ğŸ“š Exploring Chroma DB Documentation
17:47:23 ğŸ“Š Generating Embeddings and Using OpenAI Model
17:51:27 ğŸ— Setting Up OpenAI API Key
17:55:06 ğŸ“š Importing Libraries and Loading Data
18:09:37 ğŸ“š Chunking Data for Large Text Input
18:22:12 ğŸ’½ Creating Embeddings and Storing Locally
18:28:38 ğŸ”„ Retriever Creation and Document Retrieval
18:51:27 ğŸ›  Overview of project flow and data handling:
19:08:27 ğŸ“Š Understanding Model Costs
19:16:20 ğŸ›  Requirements for Open Source Models
19:27:11 ğŸ§  Understanding Llama 2
19:38:00 ğŸ¦™ Using the Llama 2 Model for Chat
20:21:19 ğŸ“ Generating responses using LLM model
20:27:14 ğŸ›  Setting up LLM model with Hugging Face pipeline
20:46:21 ğŸ›  Using Prompt Templates and LLM Chain
21:12:12 ğŸ›  Architecture Overview
21:18:24 ğŸ§© Technology Stack
21:55:15 ğŸ“š Setting Up Pinecone for Vector Database
21:59:30 ğŸ“š Loading PDF Data and Creating Text Chunks
22:20:19 ğŸ“š Storing Text Embeddings in Pinecone Vector Database
22:39:15 ğŸ“‚ Setting Up Project Structure
23:16:21 ğŸ—‚ Setting Up Environment Variables and Code Structure
23:19:13 ğŸ“ Converting Notebook Code to Modular Components
23:22:02 ğŸ“¦ Integrating Third-Party Libraries and Dependencies
23:24:26 ğŸ›  Storing Data in a Vector Database
23:42:54 ğŸŒ Developing Frontend Components with Flask
23:44:20 ğŸ“¦ Setting up environment and dependencies
23:50:36 ğŸŒ Creating web interface and user interaction
24:13:51 ğŸ“ Information about Generative AI Course
24:36:59 ğŸ¤– Comparison Between Google B and Gemini
24:13:51 ğŸ“ Information about Generative AI Course
24:22:13 ğŸ“‘ Agenda for Google Gemini LLM Session
24:29:41 ğŸ” Understanding Google Gemini LLM Model
24:36:59 ğŸ¤– Comparison Between Google B and Gemini
25:03:58 ğŸ§¾ Automating Invoice Data Extraction with LLM
25:07:01 ğŸ›  Setting up Environment and Installing Dependencies
25:08:52 ğŸ“ Planning and Architecture for Invoice Extraction Application
25:25:12 ğŸš€ Initializing Streamlit App and User Interaction
25:29:36 ğŸ–¥ Discussing Input Information for Response Generation
25:39:39 ğŸ“ Conclusion and Course Promotion
26:02:22 ğŸ“ Exploring Course Documentation
26:03:09 ğŸ¤ Appreciation and Course Selection
26:05:52 ğŸ“š Guidance for Learning Paths
26:11:37 ğŸ’¼ Career Path Discussion
26:13:52 ğŸŒ Appreciation and Enrollment Queries
26:42:55 ğŸ“Š Executing SQLite insertions and displaying records
26:46:28 ğŸ§  Configuring and loading generative AI model for query generation
26:50:09 ğŸ—ƒ Creating functions for retrieving queries from the database
26:53:10 ğŸš€ Setting up Streamlit app and defining prompts
26:59:13 ğŸ’» Setting Up Streamlit App for SQL Query Processing
27:24:17 ğŸ›  Debugging SQL Query Execution
27:36:18 ğŸ—ƒ Advanced SQL queries and nested conditions
27:46:30 ğŸ’¬ Q&A Session and Course Information
27:59:21 ğŸ¢ Discussion on industry experience and project-based learning
28:21:32 ğŸ“š Overview of Future Capabilities
28:43:00 ğŸ§  Understanding Generative AI
28:49:06 ğŸ¨ Generative Models vs. Discriminative Models
28:57:46 ğŸ’¡ Training LLM Models
29:12:23 âš¡ GPU Infrastructure Costs and Carbon Emissions
29:15:35 ğŸ“Š Training Metrics and Considerations
