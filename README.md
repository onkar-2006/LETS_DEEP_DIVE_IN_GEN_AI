# LETS_DEEP_DIVE_IN_GEN_AI
new course
00:25 🎓 Introduction to Generative AI Community Session
02:14  📚 Dashboard Walkthrough and Enrollment Process 
04:19  📋 Curriculum Overview and Instructor Introduction
07:42  📊 Detailed Curriculum Breakdown
16:49  🧠 Preparing for Generative AI and LLM Introduction
23:26  🧠 Basics of Deep Learning
27:52 🤖 Neural Network Architectures Overview
32:07 📊 Introduction to Generative AI
33:28 📝 Generative AI Models and Applications
46:12 🧠 Overview of Text and Image Generation
56:31 🔄 Addressing Sequence Mapping Issues
01:11:52 🧠 Understanding the Transformer Architecture
01:17:46 🔄 Discriminative vs Generative Models
01:25:00 🚀 Milestones in Large Language Models (LLMs)
01:44:02 📚 Accessing Resources and Engaging with the Community
01:53:42 🚀 Overview of Course Enrollment and Dashboard Setup
01:56:15 📝 Agenda for Today's Session
02:06:02 🌐 Introduction to OpenAI: History, Goals, and Milestones
02:17:19 📊 Introduction to OpenAI's API
02:28:29 💼 Job Opportunities and Interview Insights
02:38:19 📊 Checking Environment and Installing Jupyter Notebook
02:57:50 💻 Using the OpenAI Playground and setting up API keys
03:04:15 🎮 Exploring the OpenAI Playground and its functionalities
03:10:47 🤖 Understanding chat completion API and function calling
03:29:08 💡 Understanding tokenization and pricing in OpenAI API.
03:41:05 🧩 Prompt Templating with Hugging Face
03:44:03 💻 Project Development Setup and Flask Integration
04:01:10 🖥 Calling Chat Completion API
04:22:04 🖥 Extracting Textual Descriptions Using API Calls
04:42:10 📝 Extracting Origin and Destination from Arguments
04:43:59 🛫 Retrieving Flight Details
05:03:21 💻 Introduction to Function Calling and API Integration
05:10:05 🤖 Utilizing Len Chain for AI Prompting
05:34:50 🧩 Features and Capabilities of Len Chain
05:42:40 🎓 Practical Implementation and Use Cases
05:49:34 📝 Creating Prompt Templates
05:57:15 🤖 Utilizing Agents for Real-time Information Extraction
06:09:52 🛠 API Access and Documentation
06:13:07 🖥 Implementing API Calls in Code
06:15:24 📊 Real-Time Information Retrieval with Sur API
06:17:18 📚 Accessing Wikipedia Information
06:24:10 📄 Exploring Langchain Documentation
06:47:00 🔗 Sequential Chaining in LLM
06:52:10 🧩 Utilizing Sequential Chains in AI Strategy
07:24:41 🛠 Len chain project implementation agenda
08:21:35 🤖 Setting up Hugging Face Hub and accessing models
08:30:38 📦 Installation and library setup for Hugging Face
08:42:01 📚 Understanding open-source model usage
08:46:18 📝 Steps to download and utilize models locally
08:54:42 🤖 Introduction to using LennChain for generating text
08:58:12 💡 Exploring different prompts and models for text generation
09:06:32 🚀 Announcement of upcoming sessions and resources for learning
09:25:11 🚀 Publishing Code to GitHub
09:37:01 💻 Setting up Virtual Environment and .gitignore
09:42:00 📋 Listing Project Requirements in requirements.txt
09:48:43 📦 Structuring Local Package with init.py
09:58:41 💻 Installing Python packages and managing dependencies
10:06:02 📂 Exploring package metadata and project structure
10:10:07 🛠 Configuring API keys and environment variables
10:24:27 🧩 Setting Up the Environment for LLM Integration
10:30:24 🔗 Creating a Prompt Template for Quiz Evaluation
10:34:46 🤖 Connecting Components Using LLM Chain and Sequential Chain
10:40:25 🛠 Loading Data and Reading Text from a File
10:46:41 🛠 Explaining the usage of OpenAI callback for token tracking in LlamaChain
11:06:46 📁 Project setup and agenda overview
11:11:09 🛠 Adding files to project structure
11:28:38 🔒 Setting Up Logging in Python
11:41:24 📝 Using GitHub and Neuro Lab for Project Development
11:51:33 🛠 Setting up Virtual Environment and Installing Requirements
11:58:36 💻 Setting up Project Files and Importing Dependencies
12:24:59 🛠 Finalizing Application Structure
12:43:31 🧩 Generating MCQs and Displaying Results
13:02:00 📊 Demo and Troubleshooting Streamlit Application
13:04:26 🖥 Explanation of application UI and code structure
13:06:31 🚀 Tomorrow's agenda: Deployment and introduction to Vector Databases
13:12:12 📊 Generating MCQs from text data
13:16:22 💻 Preparation for AWS EC2 instance deployment
13:23:22 🚀 Starting with Generative AI
13:24:06 🛠 Setting up AWS EC2 Instance
13:37:04 📂 Cloning and Configuring Repository
13:40:55 🗝 Managing Environment Variables
13:44:44 🚀 Running the Application
13:49:09 📄 Saving generated quizzes in various formats
13:53:48 🚀 Deployment process overview and instructions
14:09:47 🧮 Understanding Vectors in 2D and 3D Spaces
14:15:08 📊 Encoding Techniques for Data Representation
14:19:06 📝 Introduction to Embedding Concept
14:32:02 🧠 Understanding Vocabulary and One-Hot Encoding
14:47:39 📊 Introduction to Vector Databases and Practical Implementation
14:53:41 📚 Enrollment Process and Dashboard Overview
15:00:41 💻 Accessing Additional Resources and Video Recordings
15:20:15 📉 Challenges with Traditional Databases
15:38:08 🗃 Use Cases of Vector Databases
15:57:27 🖥 Setting up code sharing and library installation
16:00:56 📁 Creating and uploading folders/files, troubleshooting file size
16:06:52 📑 Loading PDF data, text chunking, and preprocessing
16:19:34 📐 Extracting Embeddings with OpenAI
16:29:37 💻 Exploring Pinecone Features and Pricing
16:42:28 🧬 Implementing Similarity Search with Vector Databases
17:11:45 📝 Course Curriculum Overview
17:19:32 💻 Setting Up and Exploring Chroma DB in Jupyter Notebook
17:24:31 🔍 Overview of Chroma DB on GitHub
17:26:35 📚 Exploring Chroma DB Documentation
17:47:23 📊 Generating Embeddings and Using OpenAI Model
17:51:27 🗝 Setting Up OpenAI API Key
17:55:06 📚 Importing Libraries and Loading Data
18:09:37 📚 Chunking Data for Large Text Input
18:22:12 💽 Creating Embeddings and Storing Locally
18:28:38 🔄 Retriever Creation and Document Retrieval
18:51:27 🛠 Overview of project flow and data handling:
19:08:27 📊 Understanding Model Costs
19:16:20 🛠 Requirements for Open Source Models
19:27:11 🧠 Understanding Llama 2
19:38:00 🦙 Using the Llama 2 Model for Chat
20:21:19 📝 Generating responses using LLM model
20:27:14 🛠 Setting up LLM model with Hugging Face pipeline
20:46:21 🛠 Using Prompt Templates and LLM Chain
21:12:12 🛠 Architecture Overview
21:18:24 🧩 Technology Stack
21:55:15 📚 Setting Up Pinecone for Vector Database
21:59:30 📚 Loading PDF Data and Creating Text Chunks
22:20:19 📚 Storing Text Embeddings in Pinecone Vector Database
22:39:15 📂 Setting Up Project Structure
23:16:21 🗂 Setting Up Environment Variables and Code Structure
23:19:13 📝 Converting Notebook Code to Modular Components
23:22:02 📦 Integrating Third-Party Libraries and Dependencies
23:24:26 🛠 Storing Data in a Vector Database
23:42:54 🌐 Developing Frontend Components with Flask
23:44:20 📦 Setting up environment and dependencies
23:50:36 🌐 Creating web interface and user interaction
24:13:51 🎓 Information about Generative AI Course
24:36:59 🤖 Comparison Between Google B and Gemini
24:13:51 🎓 Information about Generative AI Course
24:22:13 📑 Agenda for Google Gemini LLM Session
24:29:41 🔍 Understanding Google Gemini LLM Model
24:36:59 🤖 Comparison Between Google B and Gemini
25:03:58 🧾 Automating Invoice Data Extraction with LLM
25:07:01 🛠 Setting up Environment and Installing Dependencies
25:08:52 📝 Planning and Architecture for Invoice Extraction Application
25:25:12 🚀 Initializing Streamlit App and User Interaction
25:29:36 🖥 Discussing Input Information for Response Generation
25:39:39 🎓 Conclusion and Course Promotion
26:02:22 🎓 Exploring Course Documentation
26:03:09 🤝 Appreciation and Course Selection
26:05:52 📚 Guidance for Learning Paths
26:11:37 💼 Career Path Discussion
26:13:52 🌍 Appreciation and Enrollment Queries
26:42:55 📊 Executing SQLite insertions and displaying records
26:46:28 🧠 Configuring and loading generative AI model for query generation
26:50:09 🗃 Creating functions for retrieving queries from the database
26:53:10 🚀 Setting up Streamlit app and defining prompts
26:59:13 💻 Setting Up Streamlit App for SQL Query Processing
27:24:17 🛠 Debugging SQL Query Execution
27:36:18 🗃 Advanced SQL queries and nested conditions
27:46:30 💬 Q&A Session and Course Information
27:59:21 🏢 Discussion on industry experience and project-based learning
28:21:32 📚 Overview of Future Capabilities
28:43:00 🧠 Understanding Generative AI
28:49:06 🎨 Generative Models vs. Discriminative Models
28:57:46 💡 Training LLM Models
29:12:23 ⚡ GPU Infrastructure Costs and Carbon Emissions
29:15:35 📊 Training Metrics and Considerations
