{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ro6GYhtN4mwH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_community.llms import Ollama\n",
        "\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "os.environ[\"langchain_api_key\"]=os.getenv(\"langchain_api_key\")\n",
        "os.environ[\"langchain_tracing_V2\"]=\"ture\"\n",
        "os.environ[\"langchain_project\"]=\"simple chatbot using ollama\"\n",
        "\n",
        "\n",
        "prompt=ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\":\"you are the helpful assitant give the answer of asked question properly \")\n",
        "        (\"user\":\"question:{question}\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "def genrate_responce(question  ,engine , tempreture ,max_token ):\n",
        "  llm=Ollama(model=engine)\n",
        "  output_parser=StrOutputParser()\n",
        "  chain=prompt|llm|output_parser\n",
        "  answer=chain.invoke('question':{question})\n",
        "  return answer\n",
        "\n",
        "\n",
        "st.title(\"the simple Q&A chatbot\")\n",
        "\n",
        "engine=st.sidebar.selectbox(\"select the opensource model model\" ,[\"spi-350 \",\"gamma-2\"])\n",
        "\n",
        "\n",
        "tempreture=st.sidebar.slider(\"tempreture\":min_value=0 ,max_value=1 , value=0.7)\n",
        "max_token=st.sidebar.slider(\"max_token\"min_value=50 ,max_value=300 , value=100 )\n",
        "\n",
        "st.write(\"go ahead and ask any question\")\n",
        "user_input=st.text_input(\"You\":)\n",
        "\n",
        "if user_input:\n",
        "  responce=genrate_responce(user_input ,engine ,  tempreture , max_token)\n",
        "  st.write(responce)\n",
        "else:\n",
        "  st.write(\"please provide the question\")\n"
      ],
      "metadata": {
        "id": "tbkqikCI6odR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}