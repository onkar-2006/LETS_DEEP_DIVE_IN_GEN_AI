{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ro6GYhtN4mwH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.promts import ChatpromtTemplate\n",
        "from langchain_core.messages import Humanmessages , AImessages\n",
        "from langchain_openai import ChatopenAI\n",
        "import streamlit as st\n",
        "import os\n",
        "from langchain_core.ouput_parsers import StrOutputParser\n",
        "import openai\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "\n",
        "os.environ[\"langchain_api_key\"]=os.getenv(\"Langchain_key\")\n",
        "os.environ[\"openai_api_key\"]=os.getenv(\"openai_api_key\")\n",
        "os.environ[\"langchain_tracking_v2\"]=\"true\"\n",
        "os.environ[\"langhchain_project_tracking\"]=\"simple qand answer Q&A chatbot\"\n",
        "\n",
        "\n",
        "prompt=ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\":\"you are the helpful assitant give the answer of asked question properly \")\n",
        "        (\"user\":\"question:{question}\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "def genrate_responce(question , api_key ,llm , tempreture ,max_token ):\n",
        "  open_ai.api_key=api_key\n",
        "  llm=ChatopenAI(model=llm)\n",
        "  output_parser=StrOutputParser()\n",
        "  chain=prompt|llm|output_parser\n",
        "  answer=chain.invoke('question':{question})\n",
        "  return answer\n",
        "\n",
        "\n",
        "st.title(\"the simple Q&A chatbot\")\n",
        "\n",
        "st.title(\"questions\")\n",
        "api_key=st.sidebar.text_input(\"enter your open_AI api kay\",type=\"password\")\n",
        "\n",
        "llm=st.sidebar.selectbox(\"select the openai_model\" ,[\"gpt-40\",\"gpt-3.5 turbo\",\"gpt-4.0 mini\"])\n",
        "\n",
        "\n",
        "tempreture=st.sidebar.slider(\"tempreture\":min_value=0 ,max_value=1 , value=0.7)\n",
        "max_token=st.sidebar.slider(\"max_token\"min_value=50 ,max_value=300 , value=100 )\n",
        "\n",
        "st.write(\"go ahead and ask any question\")\n",
        "user_input=st.text_input(\"You\":)\n",
        "\n",
        "if user_input:\n",
        "  responce=genrate_responce(user_input ,api_key , llm , tempreture , max_token)\n",
        "  st.write(responce)\n",
        "else:\n",
        "  st.write(\"please provide the question\")\n"
      ],
      "metadata": {
        "id": "tbkqikCI6odR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}