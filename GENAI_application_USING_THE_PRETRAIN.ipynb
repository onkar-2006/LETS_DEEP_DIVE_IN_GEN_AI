{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#import ing the needed librariess for the projecct"
      ],
      "metadata": {
        "id": "umy501ScwY-O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0ZgT0cUvOFb"
      },
      "outputs": [],
      "source": [
        "#import the needed labrary for the project\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "import ipykernel\n",
        "os.environ[\"OPENAI_API_KEY\"]=os.get([\"OPENAI_API_KEY\"])\n",
        "os.environ[\"LANGCHAIN_API_KEY\"]=os.get([\"LANGCHAIN_API_KEY\"])\n",
        "os.environ[\"LANGAIN_PROJECT_ID\"]=os.get([\"LANGCHAIN_PROJECT_ID\"])\n",
        "os.environ[\"LANGCHAIN_TRKING_ID\"]=\"true\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# fetching the data from the web"
      ],
      "metadata": {
        "id": "tIfOONa1wfhu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import bs4\n",
        "from langchain_community.document_loaders import WebBasedLoader\n",
        "loader=WebBasedLoader(path=\"the link of the page which u want to scrap\")\n",
        "document=loader.load()\n",
        "document\n",
        "\n"
      ],
      "metadata": {
        "id": "06UOE5Mgvw2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert the Fetching web scrap into the chunk(split the data)"
      ],
      "metadata": {
        "id": "AFlmY5rExM0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "text_splitter=RecursiveCharacterTextSplitter(chunk_size =1000 , chunk_overlap=200)\n",
        "text=text_splitter.split_document(document)\n",
        "text"
      ],
      "metadata": {
        "id": "DuD5pWJAxeN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# now we can used the two way\n",
        "either we can ussed the paid models -like the open_ai or\n",
        "we can used the free models avileble on the server/cloud -Olamma\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nfuCBqKqyCug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#the code for used the pretrain model\n",
        "from langchain.openai import openAIEmbeddings\n",
        "embedding=OpenAIEmbeddings()\n"
      ],
      "metadata": {
        "id": "p0f-PJ4yxdnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#the code for the used a free model aveleble -gamma:2b , bert-3.0 ,"
      ],
      "metadata": {
        "id": "3Wn7aUwUz2Be"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#the code for the use the free  open source model -on ollama\n",
        "#for build ing the simple app used the stremlit -the streamlit is the simple platfrom where we can deploy our model easily\n",
        "import streamlit a st\n",
        "from langchain.core.promts import ChatPromtTemplate\n",
        "from langchain_core.output_parser import StrOutputParser\n",
        "from langchain_community.llms import Ollama\n"
      ],
      "metadata": {
        "id": "wTrIhAQTz_rN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PROMPT"
      ],
      "metadata": {
        "id": "LbFDVdN_5n0a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#crete the promts\n",
        "template=ChatPromtTemplate.from_message(\n",
        "    [\n",
        "        (\"system\",\"u are the hepling assistant help the user\")\n",
        "        (\"user\" , \"Question:{questions}\")\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "qxMWI2lC4_qB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create the streamit app\n",
        "\n"
      ],
      "metadata": {
        "id": "brUkh1ja5sGR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "st.title(\"ask any queetion which u have we are redy to answer u\")\n",
        "input_text=st.text_input(\"what quetion u have in mind"
      ],
      "metadata": {
        "id": "H6HPGX8j6ftr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ollama=Ollama(\"gamma-2b\")\n",
        "output_parser=StrOutputParser()\n",
        "chain=promt|llm|output_parser\n",
        "\n",
        "if input_text:\n",
        "  st.write(chain.invoke({\"quetion\":input_text}))"
      ],
      "metadata": {
        "id": "qtkBxIy86g8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# store the model used the FAISS"
      ],
      "metadata": {
        "id": "84H5XG96zk44"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#we are almost reach toword the end of build of the model\n",
        "#the next step is to store the model somewhere called the FAISS vector database\n",
        "from langchain_community.vectorstores import FAISS\n",
        "vector_database=FAISS.from_documents(document , embedding)"
      ],
      "metadata": {
        "id": "7chmAoYTzDM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# retrive and create the chatpromt template"
      ],
      "metadata": {
        "id": "P6Lp-hTZ19RO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chain.combine_documents import create_shuff_document _chain\n",
        "from langchain_core.promts import ChatPromtTemplate\n",
        "template=ChatPromtTemplate.from_template(\n",
        "    \"ans the follwing quetion carefully\"\n",
        "  \"\"\"<context>\n",
        "   {context}\n",
        "  <context>\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "6QIZyYgIzELf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}